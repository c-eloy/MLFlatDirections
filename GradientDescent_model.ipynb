{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0b159b",
   "metadata": {},
   "source": [
    "# Gradient descent -- model file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440212f",
   "metadata": {},
   "source": [
    "In this file, we\n",
    "\n",
    "1) Read potentential from an external file\n",
    "\n",
    "2) Choose the values for the parameters: \n",
    "    - Optimizer: e.g. Adam\n",
    "    - n_points: Number of randomly initialised points\n",
    "    - n_steps: Maximum number of steps in gradient descent algorithm\n",
    "    - spread: size of the hypercube with initial data\n",
    "    - alpha: learning rate\n",
    "\n",
    "3) Perform gradient descent\n",
    "\n",
    "4) Create /Output/ directory if unavailable and store:\n",
    "    - Cloud of points and loss function into a .npy files\n",
    "    - Ancillary file stating the choices above and showing the evolution of the learning process\n",
    "\n",
    "5) Define visualisation functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a17fc",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8becca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Parameters\n",
    "##############################\n",
    "\n",
    "potential = \"x2Higgs_param_pot\"                         # .py file with potential function V(x)\n",
    "dim = 4                                                 # Number of variables\n",
    "\n",
    "time = np.datetime_as_string(np.datetime64('now'))\n",
    "time = time.replace('-','_').replace('T','_at_').replace(':','_')\n",
    "\n",
    "n_points = 100000                                       # Number of randomly initialised points\n",
    "n_steps = 2500                                          # Maximum number of steps in gradient descent algorithm\n",
    "spread = 4                                              # Initial values for the cloud of points in the hypercube [-spread/2, spread/2]^dim\n",
    "\n",
    "\n",
    "alpha=10**(-2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=alpha)\n",
    "\n",
    "optimizer_info = optimizer.get_config()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71589587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving directory\n",
    "curr_dir = os.getcwd()+'/Output/'\n",
    "\n",
    "try:\n",
    "    os.mkdir(curr_dir)\n",
    "    print(f\"Directory '{curr_dir}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{curr_dir}' already exists.\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create '{curr_dir}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Output File names\n",
    "attempt = f\"_{potential}_{n_points}_{time}\"\n",
    "\n",
    "info_file = curr_dir + 'Comments' + attempt + '.txt'\n",
    "data_file = curr_dir + 'Points' + attempt + '.npy'\n",
    "loss_file = curr_dir + 'Loss' + attempt + '.npy'\n",
    "\n",
    "\n",
    "f_info = open(info_file, 'w')\n",
    "\n",
    "\n",
    "f_info.write(f'File created on {time}')\n",
    "f_info.write(f'\\n\\nPotential : {potential}\\n')\n",
    "f_info.write('\\nOptimizer:\\n')\n",
    "\n",
    "for key, value in optimizer_info.items(): \n",
    "    f_info.write('  - %s : %s\\n' % (key, value))\n",
    "\n",
    "f_info.write('\\nEvolution:')\n",
    "f_info.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9116da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the potential\n",
    "module = importlib.import_module(potential)\n",
    "V = module.V\n",
    "\n",
    "# help(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9999f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute (||∇V||^2)\n",
    "def grad_norm_squared(V, x):\n",
    "    \n",
    "    # Record operations for automatic differentiation:\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        loss = V(x)                                     # compute V at each point\n",
    "    gradients = tape.gradient(loss, x)                  # compute ∇V at each point\n",
    "    norm_squared = tf.reduce_sum(gradients**2, axis=1)  # ||∇V||^2 at each point\n",
    "    return norm_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b28344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize the points\n",
    "x = tf.Variable(spread*np.random.rand(n_points, dim)-(spread/2), dtype=tf.float32)\n",
    "\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "\n",
    "# Learning loop \n",
    "for step in range(n_steps):  \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = tf.reduce_sum(grad_norm_squared(V, x))  # minimize ||∇V||^2 for all points\n",
    "        loss_history.append(loss)\n",
    "    \n",
    "    # Compute ||∇V||^2 with respect to x\n",
    "    gradients = tape.gradient(loss, [x])\n",
    "        \n",
    "    # Apply gradient descent for all points\n",
    "    optimizer.apply_gradients(zip(gradients, [x]))\n",
    "    \n",
    "    # Update the information in info file\n",
    "    if step % 10 == 0:\n",
    "        f_info.write(f\"\\n  Step {step}: ||∇V||^2 = {loss.numpy()}\")\n",
    "        f_info.flush()\n",
    "        \n",
    "    if np.log(loss.numpy())/np.log(10)<-6: \n",
    "        f_info.write(\"\\n\\nConverged enough\") \n",
    "        f_info.write(f\"\\n  Step {step}: ||∇V||^2 = {loss.numpy()}\")\n",
    "        break\n",
    "\n",
    "f_info.close()\n",
    "\n",
    "# Saving loss and final cloud of points\n",
    "np.save(data_file,x)\n",
    "np.save(loss_file,loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589ea90",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ec832",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d987d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute (||∇V||^2)\n",
    "def grad_norm_squared(V, x):\n",
    "    \n",
    "    # Record operations for automatic differentiation:\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        loss = V(x)                                     # compute V at each point\n",
    "    gradients = tape.gradient(loss, x)                  # compute ∇V at each point\n",
    "    norm_squared = tf.reduce_sum(gradients**2, axis=1)  # ||∇V||^2 at each point\n",
    "    return norm_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular_plot(chains):\n",
    "    data=chains\n",
    "    nsteps,ndim=chains.shape\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    for i in range(ndim):\n",
    "        ax = fig.add_subplot(ndim,ndim,i*ndim+i+1)\n",
    "        \n",
    "        ax.hist(data[:,i], 100, color=\"k\", histtype=\"step\")\n",
    "        ax.set_title(f\"x{i+1} counts\")\n",
    "\n",
    "    for i in range(ndim):\n",
    "        for j in range(i):\n",
    "            ax = fig.add_subplot(ndim,ndim,i*ndim+j+1)\n",
    "            counts,xbins,ybins,image = ax.hist2d(data[:,j],data[:,i],bins=100, norm=LogNorm(), cmap = plt.cm.rainbow)\n",
    "            plt.colorbar(image)\n",
    "            ax.contour(counts.transpose(),extent=[xbins[0],xbins[-1],ybins[0],ybins[-1]], linewidths=0.5, cmap = plt.cm.rainbow, levels = [1,100,1000,10000])\n",
    "            ax.set_xlabel(f'x{j+1}')\n",
    "            ax.set_ylabel(f'x{i+1}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def triangular_plot_slopes(chains):\n",
    "    data=chains.numpy()\n",
    "    nsteps,ndim=chains.shape\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    for i in range(ndim):\n",
    "        for j in range(i):\n",
    "            ax=fig.add_subplot(ndim,ndim,ndim*i+j+1)\n",
    "            those_slope0=np.extract(np.abs(data[:,0])>0.2,data[:,i]/data[:,j])\n",
    "            those_slope=np.extract(np.abs(those_slope0)<10,those_slope0)\n",
    "            ax.hist(those_slope,bins=100)\n",
    "            ax.set_title(f\"x{j}/x{i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4946e",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the potential\n",
    "potential = \"x2Higgs_param_pot\"                         # .py file with potential function V(x)\n",
    "module = importlib.import_module(potential)\n",
    "V = module.V\n",
    "\n",
    "\n",
    "curr_dir = os.getcwd()+'/Output/'\n",
    "time = '2024_10_30_at_23_14_20'\n",
    "n_points = 100000\n",
    "\n",
    "attempt = f\"_{potential}_{n_points}_{time}\"\n",
    "\n",
    "data_file = curr_dir + 'Points' + attempt + '.npy'\n",
    "loss_file = curr_dir + 'Loss' + attempt + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae905d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.Variable(np.load(data_file), dtype=tf.float32)\n",
    "loss_history = np.load(loss_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7146cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(f\"Number of points with ||∇V||^2 > {10**(-i)} : {sum(grad_norm_squared(V,x).numpy()>10**(-i))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5842f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangular_plot(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca464354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlatDir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
